{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ AI Peer Review Experiments: Testing Gemini's Critiques\n",
        "\n",
        "**Purpose:** This notebook systematically tests critiques raised by Gemini AI in a debate about our methodology.\n",
        "\n",
        "**Background:** After publishing our main results (AUC ~0.72), Gemini AI raised several provocative critiques:\n",
        "\n",
        "| Critique | Gemini's Claim | Experiment to Test |\n",
        "|----------|----------------|-------------------|\n",
        "| 1. Monotonic constraints = \"handcuffs\" | Forcing monotonicity prevents learning U-shaped relationships | Compare unconstrained vs constrained models |\n",
        "| 2. Reverse-causality purge was wrong | Screening tools should use whatever predicts, causality irrelevant | Test full-feature model with dental_visit, floss, mobile_teeth |\n",
        "| 3. Missingness indicators = data leakage | Learning NHANES protocol, not biology | Test deployment-ready model without missingness indicators |\n",
        "| 4. U-shaped relationships exist | BMI, age have non-linear effects | Analyze SHAP dependence plots for non-linearity |\n",
        "| 5. We \"handicapped\" the model | Artificially capping AUC at 0.72 | Test all feature combinations |\n",
        "\n",
        "**Hypothesis:** If Gemini is correct, unconstrained models with all features should achieve AUC significantly > 0.72.\n",
        "\n",
        "---\n",
        "\n",
        "## The AI Debate\n",
        "\n",
        "This notebook tests the claims from a fascinating debate between Claude AI (defending our methodology) and Gemini AI (critiquing it). Key quotes from Gemini:\n",
        "\n",
        "> \"They took a non-linear model (Gradient Boosting) capable of finding complex patterns and forced it to behave like a simple Linear Regression. They effectively 'dumbed down' the algorithm.\"\n",
        "\n",
        "> \"This confuses Etiology (what causes disease) with Prediction (who has the disease). In a screening tool, you want to know if someone hasn't visited a dentist in 5 years. That is a massive red flag for disease.\"\n",
        "\n",
        "**Let's test these claims empirically!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Section 0: Environment Setup\n",
        "============================\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "import shap\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Paths\n",
        "BASE_DIR = Path('/Users/franciscoteixeirabarbosa/Dropbox/Random_scripts/nhanes_periodontitis_ml')\n",
        "PROCESSED_DIR = BASE_DIR / 'data' / 'processed'\n",
        "FIGURES_DIR = BASE_DIR / 'figures'\n",
        "RESULTS_DIR = BASE_DIR / 'results'\n",
        "\n",
        "# Periospot colors\n",
        "PERIOSPOT_BLUE = '#15365a'\n",
        "PERIOSPOT_RED = '#6c1410'\n",
        "CRIMSON_BLAZE = '#a92a2a'\n",
        "VANILLA_CREAM = '#f7f0da'\n",
        "\n",
        "print(\"‚úÖ Environment setup complete\")\n",
        "print(f\"üìÅ Base directory: {BASE_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Load Data and Define Feature Sets\n",
        "\n",
        "We'll define multiple feature sets to test Gemini's critiques:\n",
        "1. **Primary model (v1.3):** Our published model (29 features, no reverse-causality)\n",
        "2. **Full features:** All 33 features including dental_visit, floss_days, mobile_teeth\n",
        "3. **Deployment-ready:** No missingness indicators (test \"data leakage\" claim)\n",
        "4. **Core features only:** No missingness indicators, no reverse-causality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Section 1: Load Data and Define Feature Sets\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "# Load the cleaned features dataset\n",
        "df = pd.read_parquet(PROCESSED_DIR / 'features_cleaned.parquet')\n",
        "print(f\"üìä Loaded dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "# Target variable\n",
        "y = df['has_periodontitis'].astype(int)\n",
        "print(f\"üéØ Target prevalence: {y.mean()*100:.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE SET DEFINITIONS\n",
        "# ============================================================================\n",
        "\n",
        "# Core clinical features (no missingness indicators, no reverse-causality)\n",
        "CORE_FEATURES = [\n",
        "    'age', 'sex', 'education',\n",
        "    'bmi', 'waist_cm', 'waist_height', 'height_cm',\n",
        "    'systolic_bp', 'diastolic_bp',\n",
        "    'glucose', 'triglycerides', 'hdl',\n",
        "    'smoke_current', 'smoke_former', 'alcohol_current'\n",
        "]\n",
        "\n",
        "# Missingness indicators\n",
        "MISSINGNESS_INDICATORS = [\n",
        "    'bmi_missing', 'systolic_bp_missing', 'diastolic_bp_missing',\n",
        "    'glucose_missing', 'triglycerides_missing', 'hdl_missing',\n",
        "    'smoking_missing', 'alcohol_missing',\n",
        "    'waist_cm_missing', 'waist_height_missing', 'height_cm_missing',\n",
        "    'alcohol_current_missing'\n",
        "]\n",
        "\n",
        "# Reverse-causality features (Gemini claims we should keep these)\n",
        "REVERSE_CAUSALITY_FEATURES = [\n",
        "    'dental_visit', 'floss_days', 'mobile_teeth', 'floss_days_missing'\n",
        "]\n",
        "\n",
        "# Filter to available columns\n",
        "available_cols = set(df.columns)\n",
        "CORE_FEATURES = [f for f in CORE_FEATURES if f in available_cols]\n",
        "MISSINGNESS_INDICATORS = [f for f in MISSINGNESS_INDICATORS if f in available_cols]\n",
        "REVERSE_CAUSALITY_FEATURES = [f for f in REVERSE_CAUSALITY_FEATURES if f in available_cols]\n",
        "\n",
        "# Define feature sets for experiments\n",
        "FEATURE_SETS = {\n",
        "    'primary_v13': CORE_FEATURES + MISSINGNESS_INDICATORS,\n",
        "    'full_features': CORE_FEATURES + MISSINGNESS_INDICATORS + REVERSE_CAUSALITY_FEATURES,\n",
        "    'deployment_ready': CORE_FEATURES,\n",
        "    'core_only': [f for f in CORE_FEATURES if not f.endswith('_missing')]\n",
        "}\n",
        "\n",
        "print(\"\\nüìã Feature Set Definitions:\")\n",
        "print(\"=\"*60)\n",
        "for name, features in FEATURE_SETS.items():\n",
        "    print(f\"  {name}: {len(features)} features\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüîç Reverse-causality features available: {REVERSE_CAUSALITY_FEATURES}\")\n",
        "print(f\"üîç Missingness indicators available: {len(MISSINGNESS_INDICATORS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Experiment 1 - Unconstrained vs Constrained Models\n",
        "\n",
        "**Gemini's Claim:** Monotonic constraints prevent learning U-shaped relationships, \"dumbing down\" the model.\n",
        "\n",
        "**Test:** Compare AUC of models WITH vs WITHOUT monotonic constraints.\n",
        "\n",
        "> \"They took a non-linear model (Gradient Boosting) capable of finding complex patterns and forced it to behave like a simple Linear Regression.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Experiment 1: Unconstrained vs Constrained Models\n",
        "=================================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üß™ EXPERIMENT 1: UNCONSTRAINED vs CONSTRAINED MODELS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nGemini's Hypothesis: Removing monotonic constraints will INCREASE AUC\")\n",
        "print(\"\")\n",
        "\n",
        "# Use primary feature set\n",
        "features = FEATURE_SETS['primary_v13']\n",
        "X = df[features].copy()\n",
        "\n",
        "# Define monotonic constraints\n",
        "MONOTONIC_FEATURES = {\n",
        "    'age': 1, 'bmi': 1, 'waist_cm': 1, 'waist_height': 1,\n",
        "    'systolic_bp': 1, 'diastolic_bp': 1, 'glucose': 1, 'triglycerides': 1,\n",
        "    'hdl': -1  # Higher HDL = lower risk\n",
        "}\n",
        "\n",
        "# Build constraint vector\n",
        "constraints = [MONOTONIC_FEATURES.get(f, 0) for f in features]\n",
        "\n",
        "# Setup cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "results_exp1 = []\n",
        "\n",
        "# Test both constrained and unconstrained\n",
        "for model_type in ['XGBoost', 'LightGBM']:\n",
        "    for constrained in [True, False]:\n",
        "        \n",
        "        if model_type == 'XGBoost':\n",
        "            params = {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1,\n",
        "                      'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': RANDOM_SEED,\n",
        "                      'use_label_encoder': False, 'eval_metric': 'logloss'}\n",
        "            if constrained:\n",
        "                params['monotone_constraints'] = tuple(constraints)\n",
        "            model = xgb.XGBClassifier(**params)\n",
        "        else:\n",
        "            params = {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1,\n",
        "                      'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': RANDOM_SEED,\n",
        "                      'verbose': -1}\n",
        "            if constrained:\n",
        "                params['monotone_constraints'] = constraints\n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "        \n",
        "        # Cross-validation\n",
        "        oof_preds = np.zeros(len(y))\n",
        "        for train_idx, val_idx in cv.split(X, y):\n",
        "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "            model.fit(X_train.values, y_train.values)\n",
        "            oof_preds[val_idx] = model.predict_proba(X_val.values)[:, 1]\n",
        "        \n",
        "        auc = roc_auc_score(y, oof_preds)\n",
        "        prauc = average_precision_score(y, oof_preds)\n",
        "        \n",
        "        label = \"Constrained\" if constrained else \"Unconstrained\"\n",
        "        results_exp1.append({'model': model_type, 'constrained': label, 'auc': auc, 'prauc': prauc})\n",
        "        print(f\"  {model_type} ({label}): AUC = {auc:.4f}\")\n",
        "\n",
        "# Analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä EXPERIMENT 1 VERDICT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_type in ['XGBoost', 'LightGBM']:\n",
        "    c_auc = [r for r in results_exp1 if r['model']==model_type and r['constrained']=='Constrained'][0]['auc']\n",
        "    u_auc = [r for r in results_exp1 if r['model']==model_type and r['constrained']=='Unconstrained'][0]['auc']\n",
        "    delta = u_auc - c_auc\n",
        "    \n",
        "    print(f\"\\n{model_type}: Œî AUC = {delta:+.4f}\")\n",
        "    if delta > 0.01:\n",
        "        print(f\"  ‚ö†Ô∏è GEMINI WAS RIGHT: Unconstrained performs better!\")\n",
        "    elif delta < -0.01:\n",
        "        print(f\"  ‚ùå GEMINI WAS WRONG: Constrained performs better!\")\n",
        "    else:\n",
        "        print(f\"  ‚û°Ô∏è NEGLIGIBLE: Constraints don't significantly impact performance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Experiment 2 - Full Features (With Reverse-Causality Variables)\n",
        "\n",
        "**Gemini's Claim:** Removing dental_visit, floss_days, mobile_teeth was a mistake.\n",
        "\n",
        "> \"This confuses Etiology (what causes disease) with Prediction (who has the disease). In a screening tool, you want to know if someone hasn't visited a dentist in 5 years. That is a massive red flag for disease.\"\n",
        "\n",
        "**Test:** Compare AUC with and without reverse-causality features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Experiment 2: Full Features vs Primary Model\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üß™ EXPERIMENT 2: REVERSE-CAUSALITY FEATURES\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nFeatures to test: {REVERSE_CAUSALITY_FEATURES}\")\n",
        "print(\"\")\n",
        "\n",
        "results_exp2 = []\n",
        "\n",
        "for name in ['primary_v13', 'full_features']:\n",
        "    features = [f for f in FEATURE_SETS[name] if f in df.columns]\n",
        "    \n",
        "    if len(features) == 0:\n",
        "        continue\n",
        "    \n",
        "    X = df[features].copy()\n",
        "    \n",
        "    # Unconstrained LightGBM\n",
        "    model = lgb.LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1,\n",
        "                               random_state=RANDOM_SEED, verbose=-1)\n",
        "    \n",
        "    oof_preds = np.zeros(len(y))\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        model.fit(X.iloc[train_idx].values, y.iloc[train_idx].values)\n",
        "        oof_preds[val_idx] = model.predict_proba(X.iloc[val_idx].values)[:, 1]\n",
        "    \n",
        "    auc = roc_auc_score(y, oof_preds)\n",
        "    results_exp2.append({'feature_set': name, 'n_features': len(features), 'auc': auc})\n",
        "    print(f\"  {name} ({len(features)} features): AUC = {auc:.4f}\")\n",
        "\n",
        "# Analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä EXPERIMENT 2 VERDICT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(results_exp2) >= 2:\n",
        "    primary = [r for r in results_exp2 if r['feature_set']=='primary_v13'][0]['auc']\n",
        "    full = [r for r in results_exp2 if r['feature_set']=='full_features'][0]['auc']\n",
        "    delta = full - primary\n",
        "    \n",
        "    print(f\"\\nPrimary (no reverse-causality): AUC = {primary:.4f}\")\n",
        "    print(f\"Full (with reverse-causality): AUC = {full:.4f}\")\n",
        "    print(f\"Œî AUC = {delta:+.4f}\")\n",
        "    \n",
        "    if delta > 0.02:\n",
        "        print(f\"\\n‚ö†Ô∏è GEMINI WAS RIGHT: Reverse-causality features add significant power!\")\n",
        "        print(f\"   BUT: Are we predicting disease or detecting already-known cases?\")\n",
        "    elif delta > 0.005:\n",
        "        print(f\"\\n‚û°Ô∏è SMALL IMPROVEMENT: Modest value, exclusion is defensible\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå GEMINI WAS WRONG: Negligible value from reverse-causality features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Experiment 3 - Deployment-Ready Model (No Missingness Indicators)\n",
        "\n",
        "**Gemini's Claim:** Missingness indicators are \"data leakage\" - learning NHANES survey protocol, not patient biology.\n",
        "\n",
        "**Test:** Compare model WITH vs WITHOUT missingness indicators.\n",
        "\n",
        "> \"This is arguably pure data leakage specific to the NHANES survey design. In a real-world clinical setting, a missing glucose test doesn't mean the same thing.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Experiment 3: Deployment-Ready Model\n",
        "====================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üß™ EXPERIMENT 3: MISSINGNESS INDICATORS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nMissingness indicators to test: {len(MISSINGNESS_INDICATORS)} features\")\n",
        "print(\"\")\n",
        "\n",
        "results_exp3 = []\n",
        "\n",
        "for name in ['primary_v13', 'deployment_ready']:\n",
        "    features = [f for f in FEATURE_SETS[name] if f in df.columns]\n",
        "    \n",
        "    if len(features) == 0:\n",
        "        continue\n",
        "    \n",
        "    X = df[features].copy()\n",
        "    model = lgb.LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1,\n",
        "                               random_state=RANDOM_SEED, verbose=-1)\n",
        "    \n",
        "    oof_preds = np.zeros(len(y))\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        model.fit(X.iloc[train_idx].values, y.iloc[train_idx].values)\n",
        "        oof_preds[val_idx] = model.predict_proba(X.iloc[val_idx].values)[:, 1]\n",
        "    \n",
        "    auc = roc_auc_score(y, oof_preds)\n",
        "    has_miss = name != 'deployment_ready'\n",
        "    results_exp3.append({'feature_set': name, 'has_missingness': has_miss, 'auc': auc})\n",
        "    print(f\"  {name}: AUC = {auc:.4f}\")\n",
        "\n",
        "# Analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä EXPERIMENT 3 VERDICT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(results_exp3) >= 2:\n",
        "    with_miss = [r for r in results_exp3 if r['has_missingness']][0]['auc']\n",
        "    without_miss = [r for r in results_exp3 if not r['has_missingness']][0]['auc']\n",
        "    delta = with_miss - without_miss\n",
        "    \n",
        "    print(f\"\\nWith missingness indicators: AUC = {with_miss:.4f}\")\n",
        "    print(f\"Without (deployment-ready): AUC = {without_miss:.4f}\")\n",
        "    print(f\"Œî AUC = {delta:+.4f}\")\n",
        "    \n",
        "    if delta > 0.03:\n",
        "        print(f\"\\n‚ö†Ô∏è GEMINI HAS A POINT: Missingness contributes substantially\")\n",
        "        print(f\"   For deployment outside NHANES, expect AUC ~{without_miss:.3f}\")\n",
        "    elif delta > 0.01:\n",
        "        print(f\"\\n‚û°Ô∏è MODEST CONTRIBUTION: Deployment-ready model still works\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå GEMINI WAS WRONG: Core clinical features carry the signal\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Comprehensive Summary and Final Verdict\n",
        "\n",
        "Testing all of Gemini's critiques to determine if our methodology was sound or if we \"handicapped\" our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Section 5: Final Summary\n",
        "========================\n",
        "\"\"\"\n",
        "\n",
        "# Test ALL feature combinations to find maximum AUC\n",
        "print(\"=\"*70)\n",
        "print(\"üèÜ COMPREHENSIVE TEST: MAXIMUM ACHIEVABLE AUC\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "variations = {\n",
        "    'Core only': [f for f in CORE_FEATURES if not f.endswith('_missing')],\n",
        "    'Core + missingness': FEATURE_SETS['primary_v13'],\n",
        "    'Core + reverse-causality': [f for f in CORE_FEATURES if not f.endswith('_missing')] + REVERSE_CAUSALITY_FEATURES,\n",
        "    'ALL features (Gemini optimal)': FEATURE_SETS['full_features']\n",
        "}\n",
        "\n",
        "for name, features in variations.items():\n",
        "    features = [f for f in features if f in df.columns]\n",
        "    if len(features) == 0:\n",
        "        continue\n",
        "    \n",
        "    X = df[features].copy()\n",
        "    model = lgb.LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1,\n",
        "                               random_state=RANDOM_SEED, verbose=-1)\n",
        "    \n",
        "    oof_preds = np.zeros(len(y))\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        model.fit(X.iloc[train_idx].values, y.iloc[train_idx].values)\n",
        "        oof_preds[val_idx] = model.predict_proba(X.iloc[val_idx].values)[:, 1]\n",
        "    \n",
        "    auc = roc_auc_score(y, oof_preds)\n",
        "    all_results.append({'feature_set': name, 'n_features': len(features), 'auc': auc})\n",
        "    print(f\"  {name} ({len(features)} features): AUC = {auc:.4f}\")\n",
        "\n",
        "# Save results\n",
        "experiment_summary = {\n",
        "    'experiment_date': datetime.now().isoformat(),\n",
        "    'purpose': 'Testing Gemini AI critiques',\n",
        "    'exp1_monotonic': results_exp1,\n",
        "    'exp2_reverse_causality': results_exp2,\n",
        "    'exp3_missingness': results_exp3,\n",
        "    'comprehensive': all_results\n",
        "}\n",
        "\n",
        "with open(RESULTS_DIR / 'ai_peer_review_experiments.json', 'w') as f:\n",
        "    json.dump(experiment_summary, f, indent=2, default=str)\n",
        "print(f\"\\n‚úÖ Results saved to: {RESULTS_DIR / 'ai_peer_review_experiments.json'}\")\n",
        "\n",
        "# Final verdict\n",
        "max_auc = max(r['auc'] for r in all_results)\n",
        "our_auc = 0.717\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üèÜ FINAL VERDICT: GEMINI vs OUR METHODOLOGY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                     EXPERIMENT RESULTS                          ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ Maximum achievable AUC (all features, unconstrained): {max_auc:.4f}  ‚îÇ\n",
        "‚îÇ Our published model AUC (v1.3 primary):               {our_auc:.4f}  ‚îÇ\n",
        "‚îÇ Difference:                                           {max_auc-our_auc:+.4f}  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\"\"\")\n",
        "\n",
        "if max_auc > 0.80:\n",
        "    print(\"‚ö†Ô∏è GEMINI WAS RIGHT: Significant AUC was left on the table!\")\n",
        "    print(\"   We should reconsider our methodological choices.\")\n",
        "elif max_auc > 0.75:\n",
        "    print(\"‚û°Ô∏è PARTIAL VALIDITY: Some room for improvement exists.\")\n",
        "    print(\"   Our choices were conservative but defensible.\")\n",
        "else:\n",
        "    print(\"‚ùå GEMINI WAS WRONG: AUC ceiling is ~0.72-0.73 with these features.\")\n",
        "    print(\"   Our 'realistic ceiling' claim is VALIDATED.\")\n",
        "    print(\"   The problem is feature informativeness, not methodology.\")\n",
        "\n",
        "print(\"\\nüìù RECOMMENDATIONS FOR PAPER:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"1. Report unconstrained model AUC to show constraints don't hurt\")\n",
        "print(\"2. Report 'deployment-ready' AUC for real-world applicability\")\n",
        "print(\"3. Acknowledge reverse-causality tradeoff explicitly\")\n",
        "print(\"4. Defend methodology with these empirical results\")\n",
        "\n",
        "print(\"\\n‚úÖ AI Peer Review Experiments Complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
