{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ü¶∑ NHANES Periodontitis Prediction: Temporal Validation & Gradient Boosting Benchmark\n",
    "\n",
    "**Author:** Francisco Teixeira Barbosa (Cisco @ Periospot)  \n",
    "**Date:** November 2025  \n",
    "**Project:** Replicating & Improving Bashir et al. (2022)\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ Reference Paper\n",
    "\n",
    "**Bashir NZ, Gill S, Tawse-Smith A, Torkzaban P, Graf D, Gary MT.**  \n",
    "*Systematic comparison of machine learning algorithms to develop and validate predictive models for periodontitis.*  \n",
    "**J Clin Periodontol.** 2022;49:958-969.\n",
    "\n",
    "üìÅ **Paper Location:** `scientific_articles/J Clinic Periodontology - 2022 - Bashir...pdf`\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Goals & Rationale\n",
    "\n",
    "### The Problem\n",
    "**Periodontitis** affects ~50% of US adults aged 30+, yet early prediction remains challenging.\n",
    "\n",
    "**Bashir et al. (2022)** tested 10 ML algorithms and achieved:\n",
    "- ‚úÖ **Internal validation:** AUC > 0.95 (excellent)\n",
    "- ‚ùå **External validation:** AUC ~0.50‚Äì0.60 (poor ‚Äî no better than random!)\n",
    "\n",
    "**Why the failure?** Cross-population validation (Taiwan ‚Üî US) is too strict‚Äîdifferent healthcare systems, diagnostic criteria, and populations.\n",
    "\n",
    "### Our Approach: Temporal Validation\n",
    "\n",
    "Instead of validating across populations, we validate **across time within the same population**:\n",
    "\n",
    "```\n",
    "üìÖ TRAIN:      2011-2012 + 2013-2014  (~7,000 participants)\n",
    "üìÖ VALIDATION: 2015-2016              (~3,500 participants)\n",
    "üìÖ TEST:       2017-2018              (~3,500 participants)\n",
    "```\n",
    "\n",
    "**Why temporal?**\n",
    "- ‚úÖ Mimics real-world deployment: \"Can a model trained on past data predict future patients?\"\n",
    "- ‚úÖ Same population (US adults), same methodology (NHANES)\n",
    "- ‚úÖ More realistic than random shuffling\n",
    "- ‚úÖ Tests if model captures stable biological risk vs. temporal artifacts\n",
    "\n",
    "### Methodological Improvements\n",
    "\n",
    "1. **Modern Gradient Boosting:** XGBoost, CatBoost, LightGBM (NOT tested by Bashir)\n",
    "2. **Hyperparameter Optimization:** Optuna Bayesian search\n",
    "3. **Calibration:** Isotonic regression + decision curve analysis\n",
    "4. **Interpretability:** SHAP feature importance\n",
    "5. **Survey Weights:** Sensitivity analysis with NHANES complex sampling\n",
    "6. **Reproducibility:** Versioned config, saved artifacts, git tracking\n",
    "\n",
    "### Research Gap\n",
    "\n",
    "From **Polizzi et al. (2024)** systematic review:  \n",
    "> \"None of the included articles used more powerful networks\"\n",
    "\n",
    "**Translation:** XGBoost, CatBoost, and LightGBM are **underutilized** in periodontitis prediction research.\n",
    "\n",
    "**This study fills that gap.**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Success Metrics\n",
    "\n",
    "| Metric | Bashir Internal | Bashir External | **Our Target** |\n",
    "|--------|----------------|-----------------|----------------|\n",
    "| **AUC-ROC** | 0.95+ | 0.50‚Äì0.60 | **0.75‚Äì0.85** |\n",
    "| **PR-AUC** | Not reported | Not reported | **0.60‚Äì0.75** |\n",
    "| **Calibration** | Not reported | Not reported | **Brier < 0.20** |\n",
    "| **Temporal Generalization** | N/A | Poor | **Better** |\n",
    "\n",
    "**Realistic Expectation:** Even if we don't dramatically improve AUC, demonstrating that gradient boosting **doesn't magically solve external validation** is itself a **publishable finding** that advances the field.\n",
    "\n",
    "---\n",
    "\n",
    "## üó∫Ô∏è Notebook Roadmap\n",
    "\n",
    "This notebook has **20 sections** organized into **5 phases**:\n",
    "\n",
    "### Phase 1: Data Acquisition & Labeling (Sections 1‚Äì5)\n",
    "1. Environment setup\n",
    "2. Load configuration\n",
    "3. Download NHANES data\n",
    "4. Merge components\n",
    "5. Apply CDC/AAP case definitions\n",
    "\n",
    "### Phase 2: Feature Engineering & EDA (Sections 6‚Äì7)\n",
    "6. Build 15 Bashir predictors\n",
    "7. Exploratory analysis & drift detection\n",
    "\n",
    "### Phase 3: Baseline Models (Sections 8‚Äì10)\n",
    "8. Temporal train/val/test split\n",
    "9. Preprocessing pipelines\n",
    "10. Baseline models (LogReg, RandomForest)\n",
    "\n",
    "### Phase 4: Gradient Boosting & Optimization (Sections 11‚Äì13)\n",
    "11. XGBoost with Optuna\n",
    "12. CatBoost with Optuna\n",
    "13. LightGBM with Optuna\n",
    "\n",
    "### Phase 5: Evaluation & Export (Sections 14‚Äì20)\n",
    "14. Threshold selection on validation\n",
    "15. Final test evaluation\n",
    "16. Calibration & decision curves\n",
    "17. SHAP interpretability\n",
    "18. Survey weights sensitivity\n",
    "19. Save artifacts & model card\n",
    "20. Reproducibility log\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Notes Before Starting\n",
    "\n",
    "1. **Read the Config First:** All parameters are in `configs/config.yaml`\n",
    "2. **Implement TODOs Sequentially:** Each section builds on previous ones\n",
    "3. **Test as You Go:** Run cells immediately to catch errors early\n",
    "4. **Use Autocomplete:** Function signatures are provided‚Äîlet your IDE help\n",
    "5. **Don't Skip Section 5:** CDC/AAP classification is the most critical and brittle step\n",
    "6. **Survey Weights:** For ML training, we use unweighted data (documented), but report weighted prevalence\n",
    "7. **Freeze Threshold on Val:** Never touch test set until final evaluation\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Periospot color palette loaded:\n",
      "   periospot_blue: #15365a\n",
      "   mystic_blue: #003049\n",
      "   periospot_red: #6c1410\n",
      "   crimson_blaze: #a92a2a\n",
      "   vanilla_cream: #f7f0da\n",
      "   black: #000000\n",
      "   white: #ffffff\n",
      "\n",
      "üì¶ Package Versions:\n",
      "   pandas: 2.3.2\n",
      "   numpy: 2.3.5\n",
      "   scikit-learn: 1.7.1\n",
      "   xgboost: 3.1.1\n",
      "   catboost: 1.2.8\n",
      "   lightgbm: 4.6.0\n",
      "   optuna: 4.6.0\n",
      "   shap: 0.50.0\n",
      "‚úÖ Section 1 Complete: Environment configured, seed set, Periospot style applied\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Section 1: Environment Setup & Imports\n",
    "========================================\n",
    "Set up the computational environment with all required libraries,\n",
    "apply reproducibility measures, and configure Periospot plotting style.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, brier_score_loss,\n",
    "    accuracy_score, recall_score, precision_score, f1_score,\n",
    "    confusion_matrix, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "import shap\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "from ps_plot import set_style, get_palette, save_figure\n",
    "from labels import label_periodontitis\n",
    "from evaluation import compute_metrics, plot_roc_pr, select_threshold, plot_calibration_curve\n",
    "from utils import set_seed, save_json, log_versions, save_model\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "set_style()\n",
    "palette = get_palette()\n",
    "print(\"‚úÖ Periospot color palette loaded:\")\n",
    "for name, hex_code in palette.items():\n",
    "    print(f\"   {name}: {hex_code}\")\n",
    "\n",
    "for dir_name in ['figures', 'models', 'results', 'artifacts', 'logs']:\n",
    "    Path(dir_name).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"\\nüì¶ Package Versions:\")\n",
    "print(f\"   pandas: {pd.__version__}\")\n",
    "print(f\"   numpy: {np.__version__}\")\n",
    "print(f\"   scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"   xgboost: {xgb.__version__}\")\n",
    "print(f\"   catboost: {cb.__version__}\")\n",
    "print(f\"   lightgbm: {lgb.__version__}\")\n",
    "print(f\"   optuna: {optuna.__version__}\")\n",
    "print(f\"   shap: {shap.__version__}\")\n",
    "\n",
    "print(\"‚úÖ Section 1 Complete: Environment configured, seed set, Periospot style applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ded3e4",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Configuration\n",
    "\n",
    "**Load:** `configs/config.yaml`\n",
    "\n",
    "**Contains:** NHANES cycles, temporal split, 15 predictors, CDC/AAP definitions, Optuna params, Periospot colors, survey weights\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebb7e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['2011_2012', '2013_2014'], Val: ['2015_2016'], Test: ['2017_2018']\n",
      "‚úÖ Section 2: Config loaded\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load config.yaml\n",
    "with open(\"../configs/config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "TRAIN_CYCLES = config[\"temporal_split\"][\"train\"]\n",
    "VAL_CYCLES = config[\"temporal_split\"][\"validation\"]\n",
    "TEST_CYCLES = config[\"temporal_split\"][\"test\"]\n",
    "print(f\"Train: {TRAIN_CYCLES}, Val: {VAL_CYCLES}, Test: {TEST_CYCLES}\")\n",
    "print(\"‚úÖ Section 2: Config loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aafdaf7",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download NHANES Data (XPT Files)\n",
    "\n",
    "**Download** 4 cycles √ó 9 components = 36 XPT files from CDC\n",
    "\n",
    "**Method:** `pd.read_sas(url)` ‚Üí save as parquet\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Loop cycles, download XPT files using pd.read_sas(url)\n",
    "# for cycle in CYCLES:\n",
    "#     cycle_dir = Path(f\"data/raw/{cycle}\")\n",
    "#     cycle_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     for component, file_prefix in COMPONENTS.items():\n",
    "#         url = f\"{BASE_URL}/{cycle}/{file_prefix}_{suffix}.XPT\"\n",
    "#         df = pd.read_sas(url)\n",
    "#         df.to_parquet(cycle_dir / f\"{component}.parquet\")\n",
    "print(\"‚úÖ Section 3: Data downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d61fd",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Merge Components on SEQN\n",
    "\n",
    "**Join** all components by participant ID (SEQN)\n",
    "\n",
    "**Filter:** Adults 30+\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge all components on SEQN, filter age >= 30\n",
    "# for cycle in CYCLES:\n",
    "#     dfs = []\n",
    "#     for comp in COMPONENTS:\n",
    "#         df = pd.read_parquet(f\"data/raw/{cycle}/{comp}.parquet\")\n",
    "#         dfs.append(df)\n",
    "#     merged = dfs[0]\n",
    "#     for df in dfs[1:]:\n",
    "#         merged = merged.merge(df, on=\"SEQN\", how=\"outer\")\n",
    "#     merged = merged[merged[\"RIDAGEYR\"] >= 30]\n",
    "#     merged.to_parquet(f\"data/processed/{cycle}_merged.parquet\")\n",
    "print(\"‚úÖ Section 4: Components merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8d255",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Apply CDC/AAP Case Definitions\n",
    "\n",
    "**Most Critical Section!**\n",
    "\n",
    "**Implement:**\n",
    "- Severe: CAL ‚â•6mm (‚â•2 different teeth) + PD ‚â•5mm (‚â•1 site)\n",
    "- Moderate: CAL ‚â•4mm (‚â•2 teeth) OR PD ‚â•5mm (‚â•2 teeth)\n",
    "- Mild: (CAL ‚â•3mm + PD ‚â•4mm on ‚â•2 teeth) OR PD ‚â•5mm (‚â•1 site)\n",
    "\n",
    "**Use:** `src/labels.py` `label_periodontitis()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply CDC/AAP classification using src/labels.py\n",
    "# from labels import label_periodontitis\n",
    "# for cycle in CYCLES:\n",
    "#     df = pd.read_parquet(f\"data/processed/{cycle}_merged.parquet\")\n",
    "#     df_labeled = label_periodontitis(df)\n",
    "#     df_labeled.to_parquet(f\"data/processed/{cycle}_labeled.parquet\")\n",
    "#     print(f\"{cycle} prevalence: {df_labeled['has_periodontitis'].mean():.2%}\")\n",
    "print(\"‚úÖ Section 5: CDC/AAP labels applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186641c",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Build 15 Predictors\n",
    "\n",
    "Extract Bashir predictors from NHANES variables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36867672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build predictors\n",
    "print(\"‚úÖ Section 6: Predictors built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695277e",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Exploratory Analysis\n",
    "\n",
    "Prevalence by cycle, missingness, drift\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc74dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDA plots\n",
    "print(\"‚úÖ Section 7: EDA complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84835db8",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Temporal Split\n",
    "\n",
    "Train 2011-2014, Val 2015-2016, Test 2017-2018\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea711951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split by cycle\n",
    "print(\"‚úÖ Section 8: Temporal split done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d5d35",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Preprocessing Pipelines\n",
    "\n",
    "Imputation + scaling (fit on train only)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0cb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build sklearn pipelines\n",
    "print(\"‚úÖ Section 9: Pipelines built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d6a52",
   "metadata": {},
   "source": [
    "## üîü Baseline Models\n",
    "\n",
    "LogReg, RandomForest with 5-fold CV\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137958e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train baselines\n",
    "print(\"‚úÖ Section 10: Baselines trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc453587",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ XGBoost + Optuna\n",
    "\n",
    "Hyperparameter search, early stopping\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optuna tune XGBoost\n",
    "print(\"‚úÖ Section 11: XGBoost tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6852efd",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ CatBoost + Optuna\n",
    "\n",
    "Native categorical handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optuna tune CatBoost\n",
    "print(\"‚úÖ Section 12: CatBoost tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3aec68",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ LightGBM + Optuna\n",
    "\n",
    "Fast gradient boosting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73dbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optuna tune LightGBM\n",
    "print(\"‚úÖ Section 13: LightGBM tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f377bfc",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Threshold Selection\n",
    "\n",
    "Choose policy (Youden, F1-max, Recall‚â•0.80), freeze on Val\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select threshold on Val\n",
    "print(\"‚úÖ Section 14: Threshold frozen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cb7d9",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£5Ô∏è‚É£ Final Test Evaluation\n",
    "\n",
    "Apply frozen threshold, compute all metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on Test\n",
    "print(\"‚úÖ Section 15: Test metrics computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d5c21",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£6Ô∏è‚É£ Calibration & Decision Curves\n",
    "\n",
    "Isotonic/Platt scaling, net benefit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ca535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calibration plots\n",
    "print(\"‚úÖ Section 16: Calibration done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa9220",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£7Ô∏è‚É£ SHAP Interpretability\n",
    "\n",
    "Beeswarm + bar plots\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHAP analysis\n",
    "print(\"‚úÖ Section 17: SHAP complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc29b0",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£8Ô∏è‚É£ Survey Weights Sensitivity\n",
    "\n",
    "Weighted prevalence with WTMEC2YR\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5898598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Weighted stats\n",
    "print(\"‚úÖ Section 18: Survey weights applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d90af6",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£9Ô∏è‚É£ Save Artifacts\n",
    "\n",
    "Export model, metrics, HF model card\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee403ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save all artifacts\n",
    "print(\"‚úÖ Section 19: Artifacts saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b568a3",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£0Ô∏è‚É£ Reproducibility Log\n",
    "\n",
    "Package versions, git hash, system info\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log system info\n",
    "print(\"‚úÖ Section 20: Reproducibility logged\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codecademy ML",
   "language": "python",
   "name": "codeacademy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
